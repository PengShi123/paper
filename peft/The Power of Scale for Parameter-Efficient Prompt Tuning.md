# Abstract
* Prompt Tuning 是 soft prompts。soft prompts是通过反向传播来学习的，并且可以被调整为合并来自任何数量的标记示例的信号。
* Prompt Tuning随着规模的增长而变得更有竞争力：随着模型超过数十亿个参数，我们的方法“缩小了差距”，并匹配了模型调优的强大性能（其中所有模型权重都经过了调优)。
* 因为大型模型的共享和服务成本很高，并且为多个下游任务重用一个冻结模型的能力可以减轻这种负担。
* 用soft prompts调节冻结模型可以增强域转移的鲁棒性，并实现高效的“提示集成
# 1 Introduction
* ELMo:提出冻结预先训练的模型，并学习其每层表示的任务特定权重,然而主要的自适应技术是模型调整（或“微调”），即在自适应过程中调整所有模型参数
* prompt design (or "priming")在通过文本提示调节冻结的GPT-3模型的行为方面出奇地有效，prompts 通常由任务描述和/或几个规范示例组成，这种对“冷冻”预训练模型的回归很有吸引力，尤其是在模型尺寸不断增加的情况下。单个广义模型可以同时服务于许多不同的任务，而不需要为每个下游任务提供单独的模型副本。
* 基于prompt的适应有几个主要缺点：
	* 任务描述容易出错，需要人工参与，提示的有效性受到模型输入中条件文本的限制。下游任务质量仍然远远落后于优化模型。
* Prompt Tuning冻结整个预先训练的模型，并且只允许每个下游任务的额外$k$个可调令牌被预先添加到输入文本中。这种“soft prompts”是端到端训练的，可以压缩来自完整标记数据集的信号，使我们的方法优于少数few-shot prompts，并通过模型调整缩小质量差距.
* 单独的Prompt Tuning（没有中间层前缀或任务特定的输出层）就足以与模型调优竞争。语言模型能力是这些方法取得成功的关键因素.
* “prompt ensembling”，即为同一任务学习多个提示，可以提高质量，并且比经典模型集合更有效
* contributions:
	* 1.在大型语言模型体系中，提出了prompt tuning，并展示了其与模型调优的竞争力。
	* 2.消除了许多设计选择，并显示质量和稳健性随着规模的增加而提高。
	* 3.在域转移问题上，显示prompt tuning优于模型调优。
	* 4、提出“prompt ensembling”并展示其有效性。
# 2 Prompt Tuning
* 将所有任务都视为文本生成。而不是将分类建模为给定一些输入的输出类的概率,$P_r(y|X)$,$X$ 是一个token序列 and $y$ 是单个文本标签。现在将其建模为条件生成，$Y$是表示类标签的标记序列.T5模型分类为$P_{rθ}（Y|X）$,由构成编码器和解码器的变换器的权重$θ$参数化.
* prompt是在生成$Y$的过程中为模型添加附加信息的方法.prompt是通过在输入$X$上预加一系列标记$P$来完成的，该模型使正确Y的可能性最大,$P_{rθ}(Y |[P ; X])$,保持模型参数$θ$固定.
  在GPT-3中，prompt tokens的表示形式$P =\{p_1, p_2, . . . , p_n\}$是模型嵌入表的一部分，由冻结的$θ$参数化因此，找到最佳提示需要通过手动搜索或不可微分搜索方法选择提示标记.prompt tuning消除了提示$P$由$θ$参数化的限制；相反，提示有自己的专用参数$θ_P$，可以更新.
* 虽然prompt design涉及从冻结嵌入的固定词汇表中选择prompt tokens，但prompt tuning可以被认为是使用特殊token的固定prompt，其中只有这些prompt tokens的嵌入可以更新.
* 新的条件生成现在是$P_{r_{θ；θ_P}}（Y|[P；X]）$，并且可以通过最大化$Y$(通过反向传播的可能性来训练)，同时仅对$θ_P$应用梯度更新。
* 给定一系列n个标记，$\{x_1，x_2，…，x_n\}$，T5所做的第一件事是嵌入标记，形成矩阵$X_e∈R^{n×e}$，其中$e$是嵌入空间的维数。soft prompts表示为参数$P_e∈R^{p×e}$，其中$p$是prompt的长度prompt被连接到嵌入的输入，形成单个矩阵$[P_e；X_e]∈R^{（p+n）×e}$，该矩阵然后正常地流过编码器-解码器。训练模型以最大化$Y$的概率，但仅更新提示参数$P_e$
## 2.1 Design Decisions
*  soft-prompt以与输入前的文本相同的方式调节冻结的网络的行为，因此类似单词的表示可能是一个很好的初始化点,对于分类任务，第三种选择是使用枚举输出类的嵌入来初始化提示.希望模型在输出中生成这些令牌，使用有效目标令牌的嵌入初始化提示应该使模型初始化，以将其输出限制为合法的输出类。
* 另一个设计决策是prompt的长度，作者的方法的参数代价是$E P$，其中$E$是令牌嵌入维度，$P$是prompt长度。prompt越短，必须调整的新参数就越少，因此我们的目标是找到一个仍然表现良好的最小长度.
## 2.2 Unlearning Span Corruption
* 与GPT-3等自回归语言模型不同，实验的T5模型使用编码器-编码器体系结构，并在跨度损坏目标上进行预训练,T5的任务是“重建”输入文本中的屏蔽跨度，这些跨度用唯一的sentinel tokens进行标记。目标输出文本由所有屏蔽的内容组成，由哨兵分隔，再加上最后一个哨兵。
* 由于T5跨度损坏预处理的细节，每个预训练目标都将从一个哨兵开始,虽然这种输出哨兵的“不自然”趋势很容易通过微调来克服，但由于解码器的先验无法调整，因此仅通过提示进行覆盖要困难得多。
* 在三种设置中对T5型号进行实验:
	* Span Corruption:使用预先训练的现成T5作为我们的冻结模型，并测试其为下游任务输出预期文本的能力.
	* Span Corruption + Sentinel:使用相同的模型，但为所有下游目标预先设置一个哨兵，以便更接近预训练中看到的目标.
	* LM Adaptation:继续T5的自我监督训练，进行少量的额外步骤，但使用所讨论的“LM”目标.
* 给定一个自然文本前缀作为输入,该模型必须生成自然文本延续作为输出
* 这种自适应只发生一次，生成一个冻结的模型，我们可以重用该模型，以便在任何数量的下游任务中进行即时调整。
# 3 Results
* 冷冻模型建立在所有尺寸（小型、基本型、大型、XL型、XXL型）的经过预训练的T5检查点之上。
* 训练参数：
	* cross-entropy loss
	* 0.3的学习率
	* 32的batch size
* 检查点是通过提前停止开发集来选择的，其中停止度量是数据集的默认度量，或者是使用多个度量评估的数据集的度量的平均值。
* 所有实验都是在JAX中，使用Adafactor优化器，权重衰减1e−5，$β_2$衰减0.8，参数按比例缩小。这些模型在Flax中实现
## 3.1 Closing the Gap
* consider two baselines:
	* Model Tuning:对于apples-to-apples的比较，我们分别对每个任务进行调优，就像在提示调优设置中一样。
	* "Model Tuning (Multitask):使用T5的多任务调整设置来实现更具竞争力的baseline
	* 一个单独的模型会对所有任务进行联合调优，并带有一个指示任务名称的文本前缀。
* 随着规模的增加，prompt tuning与model tuning相比更具竞争力,在XXL大小（110亿个参数）下，prompt tuning甚至与更强的多任务模型调优baseline相匹配，尽管特定任务的参数减少了20000倍以上。
## 3.2 Ablation Study
* Prompt Length:
	* 为每个模型大小训练prompt，同时在$\{1，5，20，100，150\}$中改变prompt length，并将其他设置固定为我们的默认配置。
	* 对于大多数模型大小，将提示长度增加到单个令牌之外对于实现良好性能至关重要。
	* 值得注意的是，XXL模型仍然在单个令牌提示下给出了强有力的结果，这表明模型越大，实现目标行为所需的条件信号就越少。
* Prompt Initialization:
	* 通过训练各种大小的模型，同时将其他超参数固定为其默认值，来消除即时初始化的影响。
	* 对于随机初始化：随机初始化范围为[−0.5, 0.5]当从采样词汇初始化时，将T5的句子片段词汇中的5000个最“常见”的标记限制为[Kudo和Richardson，2018]，这是根据预训练语料库中的可能性排序的.
	* 对于类标签初始化：在下游任务中为每个类的字符串表示进行嵌入，并使用它们初始化提示中的一个令牌。当类标签是多令牌时，对令牌嵌入进行平均，在较长的提示长度下，我们经常在初始化所有提示标记之前用完类标签。
	* 在较小的模型尺寸下，不同的初始化之间存在很大的差距，但一旦模型缩放到XXL尺寸，这些差异就会消失。 
	* 类标签通常保留在学习的提示中，以便最近的令牌嵌入（余弦距离）与用于初始化的令牌匹配。
* Pre-training Objective：
	* LM自适应增加了所有模型尺寸的价值，我们注意到我们最大的XXL模型是最宽容的，即使在跨度损坏的情况下也能产生强大的结果。
	* 更长的自适应提供了额外的增益，最高可达10万步。从跨度破坏到语言建模目标的“转变”不是一个微不足道的变化，而进行有效的转换需要投入培训资源（原始T5预培训步骤的10%).
	* 观察到不同模型尺寸的不稳定性，Small模型的性能优于较大的Base、Large和XL模型。对于许多任务，这些中型模型从未学会输出合法类标签，因此得分为0%。
	* 这些结果表明，使用以“跨度腐败”为目标预先训练的模型可能是不可靠的.
# 4 Comparison to Similar Approaches
* prompt tuning是参数效率最高的，对于超过10亿个参数的模型，需要不到0.01%的特定于任务的参数.提示调优使用预处理在嵌入输入之前的单个提示表示.转换器更新中间层任务表示，如由输入示例上下文化的。
* 当使用BART时，prefix tuning包括编码器和解码器网络上的前缀，而prompt tuning只需要编码器上的提示。
* WARP:prompt parameters被添加到输入层。该方法适用于掩码语言模型，依赖于[MASK]令牌和可学习的输出层将掩码投影到class logits.
* prompt tuning不需要对输入或任务特定的头进行任何更改。
* P-tuning:使用基于人类设计的模式，可学习的连续提示在整个嵌入输入中交错。
* prompt tuning:只需在输入前加上提示，就可以消除这种复杂性
* P-调优必须与模型调优结合使用，即模型联合更新提示和主要模型参数，而prompt tuning方法保持原始语言模型冻结。
* [Qin和Eisner（2021）]使用“soft words”学习提示，从预先训练的LMs中提取知识。基于手工设计的提示原型，提示相对于输入进行定位，并且每层都包含一个学习的$∆_i^l$参数，因此参数成本随模型深度而变化。
* [Logeswaran et al. (2020)]使用可学习的预先准备好的令牌使transformer模型适应各种任务，但将重点放在设计用于容纳组合任务表示的小型合成数据集上，而不是放在更大的真实世界数据集上.上述基本模型是与任务表示一起从头开始训练的小型transformer，而我们保持基本模型冻结，并使用较大的transformer研究缩放定律。
# 5 Resilience to Domain Shift
* 通过冻结核心语言模型参数，及时调整可以防止模型修改其对语言的总体理解。提示表示间接地调节输入的表示。这降低了模型对数据集过度拟合的能力通过存储特殊的词汇线索与虚假关联。这一限制表明，prompt tuning可以提高对域转移的鲁棒性，其中输入的分布在训练和评估之间不同
* zero-shot domain transfer on two tasks：
	* question answering
	* paraphrase detection
# 6 Prompt Ensembling
* 人们广泛观察到，在相同数据上通过不同初始化训练的神经模型集合可以提高任务性能，并有助于估计模型的不确定性。
* 除了存储N个模型所需的空间（例如，T5-XXL的每个副本为42GiB）之外，无论是并行还是串行运行Ndistinct模型都会产生巨大的推理成本。
* prompt tuning供了一种更有效的方式来集成预先训练的语言模型的多种改编
# 7 Interpretability
* 一个理想的可解释提示将由自然语言组成，该语言清楚地描述手头的任务，明确地向模型询问一些结果或行动，并使其易于理解为什么提示会从模型中引发这种行为。由于提示调优在连续嵌入空间而不是离散令牌空间中工作，因此解释提示变得更加困难。为了测试学习的软提示的可解释性，从冻结模型的词汇表中计算每个提示标记的最近邻居。我们使用词汇嵌入向量和提示标记表示之间的余弦距离作为相似性度量。对于给定的学习提示标记，前5个最近的邻居形成紧密的语义簇。例如，看到的词汇上相似的集群，如$\{Technology/Technologies/Technologies/techologies\}$，以及更多样但仍然密切相关的集群，例如$\{fully/fully/total\}$。这些集群的性质表明，提示实际上是在学习“类词”表示。从嵌入空间中提取的随机向量并没有显示出这种语义聚类。
* 当使用“类标签”策略初始化提示时，我们经常发现类标签通过训练而保持不变。具体地说，如果提示令牌被初始化为给定的标签，则该标签在调优后通常在学习的令牌的最近邻居中。当使用“Random Uniform”或“Sampled Vocab”方法初始化时，类标签也可以在提示的最近邻居中找到；然而，它们往往表现为多个提示令牌的邻居。这表明该模型正在学习将预期的输出类存储在提示中作为参考，并将提示初始化为输出类使其更容易、更集中。
# 8 Conclusion
* 在本文中，证明了prompt tuning是一种有竞争力的技术，可以使冻结的预训练语言模型适应下游任务。在流行的SuperGLUE基准测试中，它的任务性能可以与传统的模型调整相媲美，随着模型尺寸的增加，差距会消失。在zero shot域转移方面，我们发现及时调整可以提高泛化能力。这似乎表明，冻结通用语言理解参数并将下游学习限制在轻量级参数范围内，有助于避免对特定领域的过度拟合。除了任务质量指标之外，我们还讨论了在存储和服务成本方面转向冻结的预训练模型的吸引力。这一举措实现了高效的多任务服务，以及高效的高性能即时组装